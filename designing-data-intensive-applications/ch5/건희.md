# Ch 05. 복제

>  복제 : 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지한다.

데이터 복제가 필요한 이유는

1. 지연시간 줄이기 : 사용자와 데이터를 가까이 유지해서
2. 가용성 높이기 : 시스템 일부에 장애가 발생해도 동작에 영향받지 않게 (데이터 손실되지 않게)
3. 읽기 처리량 높이기 : 읽기 질의를 제공하는 장비의 수를 늘리기 → 읽기가 많고 쓰기가 적은 구조에서 성능에 이득을 볼 수 있다.

복제에서 모든 어려움은 복제된 데이터의 **변경 처리** 에 있으며 이번장은 이걸 설명한다.

- 노드 사이에 변경사항이 발생하면? → 복제해야 한다 (알고리즘)
    1. 단일 리더 복제
    2. 다중 리더 복제
    3. 리더가 없는 복제
- 고려해야할 트레이드오프는 없는지?
    1. 동기 vs 비동기 복제
    2. 잘못된 복제본이 생긴다면 어떻게 처리할지

## 리더와 팔로워

- replica : 데이터베이스의 복사본을 저장하는 노드 각각

그렇다면 복제 서버(replica) 를 여러개 두었을 경우, 모든 복제 서버에 동일한 데이터가 유지되고 있다는 건 어떻게 보장할까?

→ 단일 리더 복제 알고리즘으로 해결한다.

- 복제 서버 중 하나가 리더 서버이다. 클라이언트 → 데이터베이스 쓰기 요청은 리더 서버에게 전송된다.
- 다른 복제 서버는 팔로워 서버이다. (= 슬레이브 서버) 리더가 로컬 저장소에 새로운 데이터를 쓸 때마다 데이터 변경을 복제 로그나 변경 스트림의 일부로 팔로워에게 전송한다.
- 쓰기는 리더만, 읽기는 리더 or 팔로워

<img width="1039" alt="스크린샷 2020-08-28 오후 11 07 51" src="https://user-images.githubusercontent.com/45280737/91719741-d6576c80-ebd0-11ea-882b-77e0f7b452f0.png">


그럼 슬레이브가 엄청 많다면, 모든 슬레이브에 데이터가 복제된 후에 클라이언트로 응답을 내리면 너무 느린거 아닌가?

→ 그래서 이걸 보완하기 위한 복제 방식 두가지 : **동기식 vs 비동기식 복제**

- 비동기식 복제 : 리더는 팔로워에게 복제할 메시지를 전송하지만 응답을 기다려주지 않는다.
- 동기식 복제 : 리더에서 팔로워로 모든 데이터를 복사한 후에 클라이언트로 응답을 내리는 케이스
    - 동기식에서는 모든 팔로워들이 ok 를 보낼때까지 클라이언트로 응답하지 않는다.
    - 이 방식의 장점은 팔로워와 리더가 일관성있게 최신 데이터 = 같은 데이터를 유지할 수 있다는 것 ⇒ 가용성 보장
    - 하지만 동기 팔로워가 응답하지 않는다면 쓰기가 처리될 수 없다.
    - 즉, 하나의 팔로워라도 장애가 발생한다면 데이터베이스에 쓰기가 되지 않는 것.

      == 한 개 노드의 장애가 전체 시스템을 멈추게 한다? 그럼 가용성 측면에서도 복제의 목적이 흐릿해지는게 아닌지..

      ⇒ 이런 이유로 모든 팔로워와 동기식으로 동작하는 것은 비현실적이다

- 메시징 플랫폼(카프카) 에선 이걸 어떻게 설정하는지
    - Kafka Topic Replication

      ![스크린샷 2020-08-31 오후 8 01 32](https://user-images.githubusercontent.com/45280737/91719876-0868ce80-ebd1-11ea-93e0-2f9752076eb5.png)


    - replication factor (데이터 중요도에 따라 설정)

      ```bash
      bin/kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 3 –partitions 1 –topic topic02
      ```

      ```bash
      # reassign-partitions.sh

      {"version": 1,
           "partitions": [
    		    {"topic": "topic02", "partition": 0, "replicas": [2,1,3]}
    	   ]
      }
      ```

    - `unclean.leader.election.enable` : 서비스를 빠르게 정상화 vs 메시지 유실
    - [Producer acks](https://livebook.manning.com/book/kafka-in-action/chapter-4/v-14/35)

현실적으로는

- 단 하나의 팔로워하고만 동기식으로 동작하고, 나머지는 비동기식으로 동작하도록 구성한다.
- 이건 적어도 두 노드에 데이터의 최신 복사본이 유지되고 있음을 보장한다.

보통 단일 리더 복제에서는 완전 비동기식으로 동작하는데,

- 이 경우에 리더가 잘못되고 복구할 수 없다면 팔로워에 반영되지 않은 쓰기는 모두 유실된다.
- 즉, 클라이언트의 응답이 데이터의 지속성을 보장하지는 않는것.
- 하지만, 모든 팔로워가 잘못되더라도 어쨌든 쓰기 처리는 가능하다는 큰 장점이 있다.

&nbsp;

### 노드 중단 처리

시스템의 모든 노드는 장애로 인해 예기치 않게 중단될 수 있다.

혹은, 계획된 유지보수나 rolling upgrade 로 인하여 일부 노드의 동작이 멈출 수 있다.

**따라서**

- **개별 노드의 장애에도 전체 시스템이 영향받지 않아야 한다.**
- **노드가 복구된 경우 리더와 데이터 동기화가 보장되어야 한다.**

단일 리더 복제에서는 어떻게 이런 고가용성을 유지할 수 있을까?

- 팔로워 장애 : 따라잡기 복구
    1. 팔로워는 리더로부터 수신한 데이터 변경 로그를 로컬 디스크에 보관한다.
    2. 팔로워 장애 후 복구되면, 보관된 로그에서 결함이 발생하기 전에 처리한 마지막 트랜젝션을 알아낸다.
    3. 리더에 연결해서 장애가 발생한 동안 받지 못한 데이터 변경사항들을 요청할 수 있다.

&nbsp;
- 리더 장애 : 장애 복구

  반면에 리더의 장애를 처리하는 일은 까다롭다.

    1. 리더에 장애가 발생했음을 알아차려야 한다.
    2. 팔로워 중 하나를 리더로 승격시켜야 한다.
    3. 다른 팔로워는 새로운 리더로부터 데이터 변경 소식을 받아야 한다.

  &nbsp;
  이런 과정을 장애 복구(failover) 라 한다. 보통 다음과 같은 프로세스로 진행된다.

    1. 리더가 장애인지 판단한다
        - 타임아웃 : 노드들은 서로 메시지를 주고받는다. 일정 시간 동안 노드가 응답하지 않으면, 죽은 것으로 간주한다.
            - 그런데 이것도.. 어느정도의 트레이드 오프가 있는 듯하다.
                - 긴 타임아웃 : 리더 장애 ~ 복구때까지 오랜 시간이 소요될 수 있다.
                - 짧은 타임아웃 : 불필요한 장애 복구가 있을 수 있다.
                    -  일시적인 부하 증가나 네트워크 문제가 원인이었다면, 불필요한 장애복구가 상황을 더 악화시킬 수 있다.
    2. 새로운 리더를 선택한다.
        - 팔로워끼리 특정한 선출 과정이 있거나, 제어 노드에 의해 새로운 리더가 임명될 수 있다.

    3. 새로운 리더를 위해 시스템을 재설정한다.
        1. 클라이언트는 새로운 쓰기 요청을 새 리더에게 보내야 한다.
        2. 이전 리더가 복귀하더라도, 자신이 리더가 아니라 팔로워임을 눈치챌 수 있어야 한다.

  &nbsp;
  그런데 이런 과정은 잘못될 수 있는 가능성이 있다.

    - 비동기식 복제를 사용할 때
        - 새로운 리더는 메시지를 다 받지도 못했는데 old leader 가 죽어버렸다면?
        - 그런데 그 후 old leader 가 다시 클러스터에 추가된다면? → conflict data 발생
        - 그렇다고 충돌 데이터를 다 버리기엔 내구성을 보장하지 못하는 데이터베이스가 돼버림..
    - old 리더의 최신 변경사항을 가진 팔로워가 리더가 되어야 하는데 그렇지 못할 수 있다.
        - 이 경우 예전에 사용한 Auto Increment 키를 다시 사용하는 케이스
    - 특정 경우에 두 개의 노드가 모두 자신이 리더라 믿을 수 있다.
        - 이를 split brain 이라고 부르는데, 데이터가 유실될 수 있는 매우 위험한 상황이다.

&nbsp;
이걸 쉽게 해결할 수 있는 방법은 없기 때문에 자동 복구가 지원되더라도, 수동 복구를 선호하기도 한다.

그럼 단일 리더 복제는 내부적으로 어떻게 동작할까?
여기서 사용하는 다양한 복제방법을 간단히 정리해보자면..

1. 구문 기반 복제 : MySQL 5.1 이전
    - 리더는 모든 쓰기 요청을 statement 단위로 기록하고 쓰기 연산 → 그걸 팔로워한테 전송한다.
    - rdbms 에서는 모든 INSERT, UPDATE 같은 구문을 팔로워에게 전달하고, 각 팔로워는 클라이언트에서 직접 요청받은 것처럼 SQL 구문을 파싱하고 실행한다.
    - 복제가 깨진다면?
        - `NOW()` 는 서버마다 다른 값을 생성한다
        - auto increment
2. 쓰기 전 로그 배송
    - 리더가 팔로워에게 쓰기전 로그(WAL) 를 전송함
    - 팔로워가 이 로그를 처리하면 리더에서 있는 것과 정확히 동일한 데이터 구조를 구축할 수 있게 됨
    - 그러나 WAL 은 어떤 디스크블록에서 어떤 바이트를 변경했냐 와 같은 정보를 포함 → 저장소 엔진과 완전 밀접한 관계가 됨.
3. 논리적(로우 기반) 로그 복제
    - 복재 로그를 저장소 엔진 내부와 분리하기 위해서
    - 관계형 데이터베이스에서는 쓰기 연산이 표현된 로우 단위 레코드
    - 논리적 로그를 저장소 엔진 내부와 분리했기 때문에 하위 호환성을 더 쉽게 유지할 수 있고, 리더와 팔로워소프트웨어 버전이 일치하지 않아도 된다.
    - MySQL : [statement-based replication vs row-based replication](https://dev.mysql.com/doc/refman/8.0/en/replication-sbr-rbr.html)
4. 트리거 기반 복제
    - 유연성이 필요한 상황에서 : 다른 종류의 데이터베이스로 복제해야 하는 경우
    - 애플리케이션 안에서 코드 구현 : 데이터베이스 시스템에서 데이터 변경이 발생하면 자동으로 실행 → 분리된 테이블에 로깅 → 외부 프로세스가 이걸 읽어감

## 복제 지연 문제

대부분의 웹 애플리케이션은 읽기가 많고 쓰기가 적다.
이 경우에는 리더로 쓰기 요청을 보내고, 팔로워에서 읽어감으로써 애플리케이션의 성능을 향상시킬 수 있다. (읽기 요청 분산)

하지만 현실적으로 이런 아키텍쳐는 비동기식 복제에서 동작한다.

- 리더와 팔로워 사이에 데이터 복제에 딜레이가 있다면, 데이터베이스의 상태 불일치가 발생한다.
- 즉, 리더에 쓰고 팔로워에서 읽을 때 데이터가 없거나, 이전 데이터가 보이는 현상이 발생하는 것이다.
- 복제 지연 : 리더에서 발생한 **쓰기**와 팔로워에서의 **반영** 사이의 지연
- 최종적 일관성 : 이런 복제 지연은 일시적인 상태이다!
  데이터베이스에 쓰기를 멈추고 잠시 기다리면 팔로워는 결국 따라잡아서 리더랑 일치시킨다.

그럼 이런 복제 지연이 있을 땐 어떤 일이 발생하고, 그건 어떻게 해결할까?

&nbsp;
### 자신이 쓴 내용 읽기

데이터를 리더에 쓰고 팔로워에서 읽을 때

사용자가 쓰기를 수행한 직후 데이터를 읽으면 복제가 되지 않은 데이터를 읽을 수 있다. 즉, 자기가 쓴 내용이 보이지 않게 되는 것. (새로운 데이터가 복제 서버에 반영되지 않아서)

⇒ `쓰기 후 읽기 일관성`이 보장되지 않았다.

- 쓰기 후 읽기 일관성 : 다른 사람은 몰라도 내가 변경한 데이터만은 바로 봐야한다.

이건 어떻게 해결할까? (ver. 단일 리더 복제)

1. 자기가 수정한 내용은 리더에서 읽는다. 그 밖의 내용은 팔로워에서 읽는다.
2. 다른 기준을 마련한다. 예를 들면, 마지막 갱신 시간을 찾아서 마지막 갱신 후 1분 동안은 모두 리더에서 읽기를 수행한다.

또 동일한 사용자가 여러 디바이스를 사용할 때는, 디바이스 간 (cross-device) 쓰기 후 읽기 일관성이 보장되어야 한다.

&nbsp;
### 단조 읽기

비동기식 팔로워에서 발생할 수 있는 두 번째 이상 현상은 사용자가 시간이 거꾸로 흐르는 듯한 현상을 목격할 수 있다는 점이다.

이건 사용자가 *각기 다른 복제 서버에서 여러 읽기를 수행할 때* 발생할 수 있는데, 예를 들어 이런 현상이다..

![monotonic_read](https://user-images.githubusercontent.com/45280737/91720512-38fd3800-ebd2-11ea-8e20-7a24fa2eabb6.png)


1. 사용자가 최신 데이터가 반영된 팔로우 서버에서 읽는다. (첫번째 읽기 수행)
2. 그 다음에 아직 복제가 완료되지 않은 팔로우 서버에서 읽는다. (두번째 읽기 수행) ⇒ 혼란

**단조 읽기(monotonic read)** 는 이런 종류의 이상현상이 일어나지 않게 보장한다.
즉, 과거에 새로운 데이터를 읽었다면, 더이상 이전 데이터는 읽지 않도록 보장하는 것이다.

- 실현 방법 : 각 사용자의 읽기가 항상 동일한 복제 서버에서 수행되게끔 하기.
    - 복제서버 선택하기 : ~~임의선택~~ <<< 사용자 ID 의 해시를 기반으로
    - 해당 팔로우 서버 장애? → 유저를 다른 팔로우 서버로 재라우팅 필요

### 일관된 순서로 읽기

세번째 복제 지연 이상 현상은 인과성의 위반 우려.


![consistent_prefix_read](https://user-images.githubusercontent.com/45280737/91720632-6cd85d80-ebd2-11ea-820a-829e09ab9125.png)

이 현상은 리더가 여러 개일 때 발생한다. 즉, 이전에 저장된 데이터가 먼저 노출되는 경우가 발생하는 것이다.

이런 종류의 이상 현상을 방지하려면

- 일관된 순서로 읽기를 보장하여야 한다.
- 일련의 쓰기가 특정 순서로 발생한다면 → 이 쓰기를 보는 유저들은 같은 순서로 쓰여진 내용을 읽을 수 있어야 한다는 것이다.

이는 파티셔닝된(샤딩된) 데이터베이스에서 발생하는 특징적인 문제이다.

- 많은 분산 데이터베이스에서 서로 다른 파티션은 독립적으로 동작한다.
- 그래서 쓰기의 전역 순서는 없다.
- 따라서 유저가 데이터베이스에서 읽을 때 예전 상태와 새로운 상태를 동시에 확인할 수 있다 ㅠㅠ

&nbsp;

### 복제 지연을 위한 해결책

> best : 사실은 복제가 비동기식으로 동작하지만, 동기식으로 동작하는 척 하는 것

이걸 위해

- 애플리케이션 단에서 지원해주는 방법 (ex. 같은 유저는 같은 팔로워에서 읽기 등등) 은 복잡해서 실수하기 쉽다.
- 트랜젝션 : 애플리케이션을 단순하게 + 데이터베이스가 더 강력한 보장을 제공하기
- 따라서 단일 노드 트랜젝션이 존재했고, 이건 좋은 해결책이다.
- 하지만, 복제되고 파티셔닝된 데이터베이스에서는 트랜젝션 사용이 어려워졌다.
    - 성능과 가용성 측면에서 비싸다.
    - 확장 가능한 시스템에서는? -> 어쩔수없이 최종적 일관성..

## 다중 리더 복제

- 단일 리더 복제의 단점
    - 리더는 하나 + 모든 쓰기는 래당 리더를 통해서 수행된다.
    - 클라이언트와 리더 간 네트워크 중단 같은 이유로 리더에 연결할 수 없다면? → 데이터베이스에 쓰기 불가

이런 상황을 막기 위해서 리더를 여러개 둘 수 있고, 이걸 **다중 리더 설정** 이라고 한다.

이 설정에서 각 리더는 동시에 다른 리더의 팔로워 역할도 한다.

![multi_leader](https://user-images.githubusercontent.com/45280737/91720764-a01aec80-ebd2-11ea-9431-0ade1d8a8317.png)

다중 리더 복제는 단일 리더 설정과 비교해서 다음과 같은 장점이 있다.

1. 성능
    - 단일 리더 복제
        - 모든 쓰기는 인터넷을 통해 리더가 있는 데이터 센터로 이동해야 한다.
        - 따라서 쓰기 지연 시간 발생
    - 다중 리더 복제
        - 모든 쓰기는 로컬 데이터센터에서 처리한 후 비동기 방식으로 다른 데이터센터로 복제한다.
        - 물리적으로 가까이에 있는 데이터센터를 활용할 수 있기 때문에 사용자가 인지하는 성능은 더 좋다.
2. 데이터 센터 중단 내성 : 리더가 있는 데이터센터에 장애가 나면?
    - 단일 리더 복제
        - 장애 복구를 위해 다른 데이터센터에서 1개 팔로워를 리더로 승진
    - 다중 리더 복제
        - 각 데이터센터는 다른 데이터센터와 독립적으로 동작한다.
        - 따라서 고장난 데이터센터가 온라인으로 돌아왔을 때 다른 리더를 따라잡으면 된다.
3. 네트워크 문제 내성
    - 데이터센터 간 트래픽은 보통 공개 인터넷을 통해 처리한다.
    - 따라서 데이터센터 내의 로컬 네트워크보다 안정성이 떨어진다.
    - 다중 리더 복제는 데이터센터 간 비동기 복제를 사용하기 때문에 네트워크 문제에 민감하지 않을 수 있다.

이런 장점이 있음에도 다중 리더 설정은 큰 단점이 있기 때문에 주의가 필요하다.

- 동일한 데이터를 다른 두개의 데이터 센터에서 동시에 변경할 수 있다.
    - 이 때 발생하는 쓰기 충돌은 반드시 해소되어야 한다.
- 일부 데이터베이스는 다중 리더 설정을 지원하지만 새로 추가된 기능이다.
    - 따라서 데이터베이스의 auto increment, 무결성 제약 같은 기능과 뜻밖의 상호작용이 발생하거나 실수가 있을 수 있다.

### 쓰기 충돌 다루기

위키 페이지를 동시에 두 사용자가 편집한다고 가정해본다.
이 변경을 비동기로 복제시킬 때 충돌이 감지된다. 이건 단일 리더 복제에서는 안일어남.

<img width="616" alt="write_conflet" src="https://user-images.githubusercontent.com/45280737/91720592-5cc07e00-ebd2-11ea-8fe0-a25955fd7aab.png">


다중 리더 설정에서

- 두 쓰기는 모두 성공하며
- 충돌은 이후 특정 시점에서 비동기로만 감지한다.

따라서 다중 리더 복제의 가장 큰 문제는 쓰기 충돌이다.
이건 같은 데이터를 각기 다른 리더에서 두 사용자가 변경했을 때 인데, 어떤 데이터로 덮어써야 할지 모호하다.

&nbsp;
### 충돌 회피

충돌을 처리하는 가장 간단한 전략은 충돌을 피하는 것이다.

- 많은 다중 리더 복제 구현 사례에서 충돌을 잘 처리하지 못하기 때문에 충돌을 피하는 전략을 취하는 것이 자주 권장된다.
- 특정 레코드의 모든 쓰기가 동일한 리더에서 처리되도록 하면 충돌은 발생하지 않는다.
    - 특정 유저 요청은 어떤 1개의 데이터센터에서 처리 + 이후 각 데이터센터 내의 리더를 사용해 읽기와 쓰기
    - 보통 지리적 근접성을 이용해서 특정 유저의 요청이 특정 데이터센터 (홈 데이터센터) 에서 처리된다.

그렇다면 홈 데이터센터에 장애가 발생했거나 유저가 지역을 이동한다면? => 충돌회피가 실패한다.

&nbsp;

### 일관된 상태 수렴

동시 요청이 왔을 때, 데이터베이스에서 충돌은 수렴 방식으로 해결되어야 한다.
- 모든 복제서버가 최종적으로 동일하다는 사실을 보장
- 모든 복제 서버는 동일한 최종값을 전달받아야 한다.

따라서 이걸 위해선 수렴 충돌 해소가 필요한데, 다음과 같은 방법들을 쓸 수 있다.

1. 각 쓰기에 고유 ID 를 부여하고 가장 높은 ID 를 가진 쓰기를 고른다.
    - 다른 쓰기는 버리는 것
    - 데이터 유실 위험이 있다.
2. 각 복제 서버에 고유 ID 를 부여하고 높은 숫자의 복제 서버에서 생긴 쓰기를 우선적으로 적용한다.
    - 다른 쓰기는 버리는 것
    - 데이터 유실 위험이 있다.
3.  어떻게든 병합하기 ("B" + "C" ⇒ "B/C")
4. 명시적 데이터 구조에 충돌을 기록해서 모든 정보 보존 → 사용자에게 메시지를 보여준다.

&nbsp;
### 사용자 정의 충돌 해소 로직

충돌을 해소하는 가장 적합한 방법은 애플리케이션에 따라 다르다. 즉, 애플리케이션 자체에서 충돌을 해소해주어야 한다.

이런 충돌 해소는

- 데이터 쓰기 수행 중에 충돌감지 → 충돌 핸들러 호출 이 되거나,
- 일단 모든 충돌 쓰기를 저장하고 → 다음번 데이터 읽기에서 해소 로직을 적용시킨다.

이런 사용자 정의 충돌 해소 로직을 사용하는 예를 하나 보자면..

- [아마존의 충돌 해소 로직](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)
    - 참고 : amazon's highly available key-value store - 4.3 Replication
    - 모든 데이터 변경은 다른 복제 서버에 비동기 복제 되는 프로세스

  <img width="660" alt="스크린샷 2020-08-30 오후 4 35 39" src="https://user-images.githubusercontent.com/45280737/91721259-6eeeec00-ebd3-11ea-920d-698e6ae0ff79.png">

&nbsp;
### 다중 리더 복제 토폴로지

복제 토폴로지는 쓰기를 한 노드에서 다른 노드로 전달하는 통신 경로를 설명한다.

- 리더가 2개 노드 ⇒ 가능한 토폴로지는 1개
- 리더가 둘 이상이면 ⇒ 다양한 토폴로지가 가능하다.

크게 세가지 예를 보자면,

<img width="1175" alt="스크린샷 2020-08-30 오후 4 58 14" src="https://user-images.githubusercontent.com/45280737/91721327-8a59f700-ebd3-11ea-8ad1-ae4984c87d0d.png">

1. 원형 토폴로지
    - MySQL 에서 디폴트로 지원
    - 각 노드는 1개 노드로부터 쓰기를 받고 → 자기꺼 갱신 → 다른 1개 노드에 전달
2. 별모양 토폴로지
    - 지정된 루트 노드가 존재
    - 루트 노드 하나가 다른 모든 노드에게 쓰기를 전달한다.
3. 전체 연결 토폴로지
    - 모든 리더가 각자의 쓰기를 다른 모든 리더에게 전송하는 general case

&nbsp;
여기서 무한 복제 루프를 방지하기 위해서

- 각 노드에 고유 식별자가 있고,
- 복제 로그에서 각 쓰기는 거치는 모든 노드의 식별자가 태깅된다.

&nbsp;
그러나 원형 토폴로지 / 별 모양 토폴로지는 단점이 존재한다.

- 하나의 노드에 장애가 발생하면 → 장애가 다른 노드 간 복제 메시지 흐름에 방해를 준다.
- 따라서 해당 노드가 복구될 때까지 통신이 불가능.
- 이런점에서 전체 연결 토폴로지가 내결함성이 더 좋다.

그럼 전체 연결 토폴로지는 문제가 없나..? ~~아니다~~


<img width="1175" alt="스크린샷 2020-08-30 오후 5 11 29" src="https://user-images.githubusercontent.com/45280737/91721425-b1182d80-ebd3-11ea-80bc-3f1e2ec4dda5.png">

일부 네트워크 연결이 다른 연결보다 빠르다면, 일부 복제 메시지가 다른 메시지를 추월할 수 있다.

&nbsp;
## 리더 없는 복제

= 리더 개념 X
= 모든 복제 서버가 클라이언트로부터 쓰기를 직접 받을 수 있게

이 방식은 아마존이 내부 DynamoDB 시스템에서 사용한 후 다시 데이터베이스 아키텍쳐로 유행했다.
- 다이나모 스타일 : cassandra, 리악, 볼드모트

시스템마다 이걸 구현하는 방법은 다름..
- 클라이언트가 직접 여러 복제 서버에 쓰기를 전송
- Coordinator node(주키퍼와 같은)가 클라이언트를 대신해서 이걸수행
    - 리더 데이터베이스와 달리 coordinator node 는 특정 순서로 쓰기를 수행하지는 않는다.

&nbsp;
### 노드가 다운되었을 때 데이터베이스에 쓰기

![broken_node](https://user-images.githubusercontent.com/45280737/91721753-3ac7fb00-ebd4-11ea-82d0-30424c24d9b2.png)

단일 리더 복제에서는 쓰기처리를 계속하기 위해선 장애 복구가 필요하다.
하지만 리더 없는 복제 설정에서는 장애복구가 필요하지 않는다.

- 사용할 수 없었던 복제 서버가 다시 온라인이 되었을 때,
  다른 클라이언트가 해당 노드에서 데이터를 읽는다면 응답으로 오래된 데이터를 받아올 수 있다.

- 이를 해결하기 위해서는
    - 읽기 요청을 병렬로 여러 노드에 전송한다.
    - 클라이언트는 여러 노드에서 다른 응답을 받을 수 있다. (최신 값 + 오래된 값)
    - 이때는 버전을 확인하여 최신 데이터를 결정할 수 있다.

&nbsp;
### 읽기 복구와 안티 엔트로피

위와 같은 경우에 복구된 노드의 오래된(outdated) 데이터를 업데이트하여야 한다.

누락된 쓰기 데이터를 어떻게 업데이트 할 수 있을까?
다이나모 스타일 데이터스토어는 다음 두가지 메커니즘을 사용한다.

1. 읽기 복구
    - 클라이언트가 여러 노드에서 병렬로 읽기를 수행하면 오래된 응답을 감지할 수 있다.
    - 이 때 복제 서버에 새로운 값을 업데이트한다.
2. 안티 엔트로피 처리
    - 백그라운드 프로세스를 두고 복제 서버 간 데이터 차이를 지속적으로 찾아, 누락된 데이터를 하나의 복제 서버에서 다른 복제 서버로 복사한다.
    - 안티 엔트로피 처리가 없으면 → 읽기가 아예 없었던 데이터는 복제본에서 누락될 수 있다.

&nbsp;
### 읽기와 쓰기를 위한 쿼럼

복제 서버들 중에서 쓰기를 성공했다고 간주하는 범위는 어느정도일까? 이게 설정되면 어떻게 되는걸까?

n 개의 복제서버가 있을 때
- 모든 쓰기는 w 개의 노드에서 성공해야 쓰기가 확정되고
- 모든 읽기는 최소한 r 개의 노드에 질의해야 한다.

&nbsp;
이 때
- w + r > n 이면 읽을때 최신 값을 얻을 것으로 기대할 수 있다.
- 이런 r 과 w 를 따르는 읽기와 쓰기를 정족수 (쿼럼) 읽기와 쓰기라고 부른다.
    - 읽기나 쓰기가 성공했다고 건주하려면 n 개의 노드 중 몇개의 노드에서 성공을 확인해야 하는지
    - 내가 얼마나 많은 노드를 기다려야 할지 결정한다.

&nbsp;
상황에 따라 선택하기
- 일반적인 선택 : n 은 홀수 (보통 3 이나 5), w = r = (n+1) / 2 로 설정
- 예를들어
    - 쓰기가 적고 읽기가 많은 작업부하? w=n, r=1
        - 읽기는 빨라지지만 노드 하나가 장애 상황일때 모든 데이터베이스 쓰기가 실패한다..

쿼럼 조건이 w+r > n 일때는 다음과 같이 flexibility 를 줄 수 있다.

- w < n 이면 노드 하나를 사용할 수 없어도 여전히 쓰기 처리가 가능하다.
- r < n 이면 노드 하나를 사용할 수 없어도 여전히 읽기를 처리할 수 있다.

![follower_broken](https://user-images.githubusercontent.com/45280737/91722035-a5793680-ebd4-11ea-8b5d-6b0615ba2d34.png)


### 정족수 일관성의 한계

w + r > n 이 되면, 일반적으로 모든 읽기는 키의 최신 값을 반환할 수 있다고 기대한다.


그럼 w + r ≤ n 로 셋팅하는건..?

- 오래된 값을 읽을 확률이 높아질 수 있지만
- 네트워크 중단 등으로 많은 복제 서버가 응답하지 않는 사태에서 비교적 이득을 볼 수 있을 듯하다..

하지만 이런 쿼럼이 읽기 시 최근 값을 반환해주는 건 그렇게 간단하지 않다 ㅠ
매개변수 w 와 r 로 오래된 값을 읽는 확률을 조절할 수는 있지만, 이를 절대적으로 보장할 수는 없다.

&nbsp;
### 느슨한 쿼럼과 암시된 핸드오프

적절히 설정된 쿼럼
- 데이터베이스는 장애 복구 없이 개별 노드 장애를 허용한다.
- 개별 노드의 응답이 느려지는 것도 허용한다.

하지만 네트워크 문제 등으로 즉시 응답 가능한 노드가 w 나 r 보다 적다면?
- 그냥 w, r 노드 쿼럼을 충족하지 못했으니까 에러를 반환할까?
- 아니면 일단 쓰기를 받아들이고, 셋팅된 n 개 노드에 포함되지는 않지만 연결할 수 있는 노드에 기록해버릴까? => "느슨한 쿼럼"
    -  지정된 n 개 노드 외에 또다른 노드가 값을 위해 포함될 수 있다.

여기서 발생하는 암시된 핸드오프란, 다음과 같다.

- 암시된 핸드오프 : 네트워크 장애 상황이 해제되면 한 노드가 다른 노드를 위해 일시적으로 수용한 모든 쓰기를 해당 홈 노드 (n 개에 포함됐던 노드) 로 전송한다.

따라서 느슨한 쿼럼을 정리하면
- 쓰기 가용성을 높이는 데 유용하다.
- 결국 w 개의 노드를 어쨌거나 사용할 수 있는 동안은 데이터베이스가 쓰기를 받아들인다..
- 최신 값이 일시적으로 n 이외의 일부 노드에 기록된다
    - w + r > n 인 경우에도 키의 최신값을 읽는다고 보장하지 못한다.
    - 암시된 핸드오프가 끝날때까지는 `r 노드의 읽기 = 최근 저장된 데이터를 본다` 를 보장할 수 없다.

&nbsp;
### 동시 쓰기 감지

다이나모 스타일 데이터베이스는 여러 클라이언트가 동시에 같은 키에 쓰는 걸 허용한다
= 느슨한 쿼럼을 사용하지 않더라도, 충돌이 발생할 수 있다.

이런 상황에서 제일 문제되는 것
- 다양한 네트워크 지연과 부분적인 장애 때문에 이벤트가 서로 다른 노드에 다른 순서로 도착할 수 있다는 것

두 클라이언트가 키 X 를 동시에 세 노드 데이터스토어에 기록하는 상황에서는..

<img width="1175" alt="스크린샷 2020-08-30 오후 9 16 12" src="https://user-images.githubusercontent.com/45280737/91722954-01908a80-ebd6-11ea-8243-bdb7a4848c4b.png">

- 노드들은 영구적으로 일관성이 깨진다. = 최종적인 일관성을 달성하지 못했다.

어떻게 해결하지?

최종적으로 값을 수렴하기 위한 가장 일반적인 방법은
각 복제본이 가진 "예전" 값을 버리고 가장 "최신" 값으로 덮어쓰는 방법이다.

그런데 "최신" 은 어떻게 판단할까?

- 타임스탬프로 판단해서, 상대적으로 더 작은 타임스탬프의 쓰기가 동시에 들어오면 무시하는 전략
  ⇒ 최종 쓰기 승리 (LWW) 는 카산드라에서 유일하게 제공하는 충돌해소 방법이다

- 동일한 키에 여러번의 동시 쓰기가 있다면?
    - 클라이언트에게는 모두 성공이 반환됨
    - 쓰기 중 하나만 남고 다른 쓰기는 모조리 무시되는 것.
    - 손실 데이터를 허용하지 않는 상황이면 적합하지 않다

### "이전 발생" 관계

그럼 두가지 작업이 동시에 수행됐는지는 어떻게 결정할까?

- 동시성의 의미를 정의하는 핵심은 → 한 작업이 다른 작업 **이전** 에 발생했는지 이다.
    - 작업 B 가 작업 A 에 대해 알고 있거나, A 에 의존적이거나, A 작업을 기반으로 하거나 .. 이런 상황이면
    - 작업 A 는 작업 B 의 **이전 발생** 이다.
- 반대로, 어떤 작업도 다른 작업에 대해 알지 못하는 상황이면 **동시 작업** 이라고 말한다.
    - ~~물리적인.. 정확한 시간으로 따지는게 아니였다~~

이렇게 정의 내린다면, 작업 상황은 두가지로 나뉜다.

1. 한 작업이 다른 작업 전에 발생한다면 → 나중 작업은 이전 작업을 덮어쓸 수 있다.
2. 작업이 동시에 발생했다면 → 충돌을 해소해야 한다.

그럼 두 작업이 동시에 발생했는지, 또는 하나가 이전에 발생했는지는 어떻게 결정될까?

<img width="1175" alt="스크린샷 2020-08-30 오후 10 31 03" src="https://user-images.githubusercontent.com/45280737/91723735-3224f400-ebd7-11ea-9ad6-8b4ad8693e42.png">


서버는 버전 번호를 보고 두 작업이 동시에 수행됐는지 여부를 체크할 수 있는데, 다음 프로세스로 동작한다.

1. 기록한 값은 새로운 버전 번호를 갖고 저장된다.
    - 서버가 모든 키에 대한 버전 번호를 갖고 있다.
2. 클라이언트가 키를 읽을 때 서버는 최신 버전 + 덮어쓰지 않은 모든 값을 반환한다.
    - 클라이언트는 쓰기 전에 키를 읽어야 한다.
3. 클라이언트가 키를 기록할땐 이전 읽기의 버전 번호를 포함 + 이전 읽기에서 받은 모든 값을 합친다.
4. 그걸 받는 서버 입장
    - 해당 버전 이하의 모든 값은 덮어쓰기 가능
    - 근데 그거보다 높은 버전 번호의 모든 값은 그대로 유지해야한다. = 동시에 발생했다고 감지한다.

이 방법은

- 어떤 데이터도 그냥 자동으로 삭제되지는 않지만
- 클라이언트쪽에서 추가 작업이 있다.
    - 여러 작업이 동시에 발생하면 클라이언트는 동시에 쓴 값을 따로 다 합쳐서 정리해야 한다.
    - 리악에서는 이런 동시 값을 형제 값이라고 한다.

형제 값은 그럼 어떻게 머지하지?

1. 합집합
    - 장바구니의 상품 삭제 기능..
2. 툼스톤 : 형제값 병합할때 상품을 제거했음을 표시하기! (해당 버전 번호에)

### 버전 벡터

복제 서버가 여러개 있지만 리더가 없는 복제에선 알고리즘이 어떻게 변할까?

- ~~단일 버전 번호~~ → 키 당 버전 번호 + 복제본 당 버전 번호
    - 각 복제본은 쓰기 처리할때 자체 버전 번호를 증가시키고, 다른 복제본의 버전 번호도 추적해야함.

여기서 버전 벡터란,
모든 복제서버의 버전 번호 모음이다.

- 리악 2.0 : dotted version vector
    - 값을 읽을 때 복제 서버에서 클라이언트로 버전 벡터 전송
    - 이후에 값이 기록될 때 데이터베이스로 다시 전송
    - 버전 벡터를 사용해서 덮어쓰기와 동시 쓰기를 구분한다.

## 정리

복제는 다양한 용도로 사용될 수 있다.

1. 고가용성
    - 한 장비가 다운될 때도 시스템이 계속 동작하게 한다.
2. 연결이 끊긴 작업
    - 네트워크 중단이 있을 때도 애플리케이션이 계속 동작하게 한다.
3. 지연시간
    - 지리적으로 사용자에게 데이터를 가까이 배치해 사용자가 더 빠르게 작업할 수 있게 한다.
4. 확장성
    - 복제본에서 읽기를 수행해 단일 장비에서 다룰 수 있는 양보다 많은 양의 읽기 작업을 처리할 수 있다.

복제는 매우 까다로운 문제다.

동시성 문제를 포함해서 잘못될 수 있는 모든 사항을 주의 깊게 생각하고 그 결함의 결과를 주의 깊게 다뤄야 한다.

- 사용할 수 없는 노드
- 네트워크 중단

아울러 복제에 대한 세가지 주요 접근 방식이 있었다.

1. 단일 리더 복제
    - 클라이언트는 모든 쓰기를 단일 노드로 전송
    - 리더는 데이터 변경 스트림을 다른 복제 서버로 전송한다.
    - 읽기는 모든 복제 서버가 할 수 있지만 오래된 값이 나올 수 있다.
    - 이해가 쉽고 충돌 해소에 대한 우려가 없다.
2. 다중 리더 복제
    - 클라이언트는 쓰기를, 그걸 받아들일 수 있는 노드로 전송한다.
    - 리더는 데이터 변경 스트림을 다른 모든 리더와 팔로워에게 전송한다.
    - 결함 노드, 네트워크 중단, 지연시간 급증이 있는 상황에서 더 견고하다.
    - 일관성 보장이 어렵다.
3. 리더 없는 복제
    - 클라이언트는 각 쓰기를 여러 노드로 전송한다.
    - 클라이언트는 오래된 데이터를 감지하고 이를 바로잡기 위해 병렬로 여러 노드에서 읽는다.
    - 결함 노드, 네트워크 중단, 지연시간 급증이 있는 상황에서 더 견고하다.
    - 일관성 보장이 어렵다.

복제는 동기 혹은 비동기로 이뤄진다.

- 동기 vs 비동기
    - 결함이 있을 때 시스템 작동에 중요한 영향을 미친다.
- 비동기 복제는
    - 복제 지연이 증가하고 서버 장애가 발생하면 어떤 일이 일어나고 있는지 판단해야 한다.
    - 리더가 장애 → 팔로워를 비동기로 새로운 리더로 승진시키면 최근 커밋된 데이터를 잃을 위험이 있다.

그리고 애플리케이션이 복제 지연시 어떻게 동작해야 하는지, 일관성 모델을 살펴보았다.

1. 쓰기 후 읽기 일관성
    - 사용자는 자신이 제출한 데이터만은 항상 볼 수 있어야 한다.
2. 단조 읽기
    - 사용자가 어떤 시점의 데이터를 본 순간, 이전 시점의 데이터를 나중에 볼 수 없다.
3. 일관된 순서로 읽기
    - 데이터를 인과에 맞게 보아야 한다. 쓴 순서대로 읽어야 한다.

여러 쓰기가 동시에 발생하는 상황에선 쓰기 충돌이 발생할 수 있다.
- 한 작업이 다른 작업 이전에 발생했는지, 동시에 발생했는지 판단하는 알고리즘
- 동시 갱신을 머지해서 충돌을 해결하는 방법

## Reference

- [http://astrod.github.io/data/2019/08/11/데이터-중심-애플리케이션-5장-복제/#다중-리더-복제](http://astrod.github.io/data/2019/08/11/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%91%EC%8B%AC-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-5%EC%9E%A5-%EB%B3%B5%EC%A0%9C/#%EB%8B%A4%EC%A4%91-%EB%A6%AC%EB%8D%94-%EB%B3%B5%EC%A0%9C)
- [https://livebook.manning.com/book/kafka-in-action/welcome/v-14/](https://livebook.manning.com/book/kafka-in-action/welcome/v-14/)
- [https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)
- [https://www.popit.kr/kafka-운영자가-말하는-topic-replication/](https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-topic-replication/)
- [https://dev.mysql.com/doc/refman/8.0/en/replication-sbr-rbr.html](https://dev.mysql.com/doc/refman/8.0/en/replication-sbr-rbr.html)